{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Paulo Kim\n",
    "\n",
    "Nome: Rodrigo Coelho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename = 'iPhone_X.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train = train.iloc[:,:2]\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test = test.iloc[:,:2]\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Nós pegamos como produto o iPhone X. Para sua classificação, dividimos os tweets em:\n",
    "\n",
    "* Propaganda/oferta (0)\n",
    "* Muito irrelevante (1)\n",
    "* Irrelevante (2)\n",
    "* Relevante (3)\n",
    "* Muito relevante (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função cleanup que realiza a filtragem de caracteres desnecessários\n",
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    text_subbed_list = text_subbed.split()\n",
    "    \n",
    "    for word in text_subbed_list:\n",
    "        if '@' in word or word[:5] == 'https':\n",
    "            text_subbed_list.remove(word)\n",
    "        else:\n",
    "            pass\n",
    "    return ' '.join(text_subbed_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para realizar a limpeza\n",
    "for i in range(len(train)):\n",
    "    train.at[i,'Treinamento'] = cleanup(train.Treinamento[i]).lower() \n",
    "                                                                      \n",
    "    \n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o total de palavras no conjunto dos tweets \n",
    "total_palavras = 0 \n",
    "for phrase in train.Treinamento:\n",
    "    total_palavras += len(phrase.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montagens das séries e tabelas relativas para cada classificação\n",
    "\n",
    "Filtragem do dataframe para cada classficação, para assim montar as tabelas com as probabilidades de cada palavra dada uma classificação\n",
    "\n",
    "(TOKKI) Aqui não gostei muito do jeito que eu fiz, queria ter feito algo mais \"limpo\", pode mudar se tiver uma ideia melhor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a lista de palavras da classficação Propaganda/Oferta (0) em uma série\n",
    "lista_palavras_class_0 = []\n",
    "palavras_class_0 = train.loc[train.Classificação == 0,:]\n",
    "\n",
    "for phrase in palavras_class_0.Treinamento:\n",
    "    lista_palavras_class_0 += phrase.split()\n",
    "    \n",
    "series_palavras_class_0 = pd.Series(lista_palavras_class_0)\n",
    "series_palavras_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a lista de palavras da classficação Muito Irrelevante (1) em uma série\n",
    "lista_palavras_class_1 = []\n",
    "palavras_class_1 = train.loc[train.Classificação == 1,:]\n",
    "\n",
    "for phrase in palavras_class_1.Treinamento:\n",
    "    lista_palavras_class_1 += phrase.split()\n",
    "    \n",
    "series_palavras_class_1 = pd.Series(lista_palavras_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a lista de palavras da classficação Irrelevante (2) em uma série\n",
    "lista_palavras_class_2 = []\n",
    "palavras_class_2 = train.loc[train.Classificação == 2,:]\n",
    "\n",
    "for phrase in palavras_class_2.Treinamento:\n",
    "    lista_palavras_class_2 += phrase.split()\n",
    "    \n",
    "series_palavras_class_2 = pd.Series(lista_palavras_class_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a lista de palavras da classficação Relevante (3) em uma série\n",
    "lista_palavras_class_3 = []\n",
    "palavras_class_3 = train.loc[train.Classificação == 3,:]\n",
    "\n",
    "for phrase in palavras_class_3.Treinamento:\n",
    "    lista_palavras_class_3 += phrase.split()\n",
    "    \n",
    "series_palavras_class_3 = pd.Series(lista_palavras_class_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando a lista de palavras da classficação Muito Relevante (4) em uma série\n",
    "lista_palavras_class_4 = []\n",
    "palavras_class_4 = train.loc[train.Classificação == 4,:]\n",
    "\n",
    "for phrase in palavras_class_4.Treinamento:\n",
    "    lista_palavras_class_4 += phrase.split()\n",
    "    \n",
    "series_palavras_class_4 = pd.Series(lista_palavras_class_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a quantidade de cada palavra dada a classificação\n",
    "tabela_palavra_class_0 = series_palavras_class_0.value_counts()\n",
    "tabela_palavra_class_1 = series_palavras_class_1.value_counts()\n",
    "tabela_palavra_class_2 = series_palavras_class_2.value_counts()\n",
    "tabela_palavra_class_3 = series_palavras_class_3.value_counts()\n",
    "tabela_palavra_class_4 = series_palavras_class_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabela_palavra_class_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a probabilddiade de uma palavra pertencer a respectiva classificação   \n",
    "P_0 = len(lista_palavras_class_0) / total_palavras\n",
    "P_1 = len(lista_palavras_class_1) / total_palavras\n",
    "P_2 = len(lista_palavras_class_2) / total_palavras\n",
    "P_3 = len(lista_palavras_class_3) / total_palavras\n",
    "P_4 = len(lista_palavras_class_4) / total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing\n",
    "smoothing = {\n",
    "    \n",
    "    'V': 10**3,\n",
    "    'alpha': 1\n",
    "}\n",
    "\n",
    "# Funções resposáveis em calcular as probabilidades com a aplicação do smoothing\n",
    "\n",
    "def prob_frase_dado_class_0(frase):\n",
    "    prob = 1\n",
    "    for palavra in frase.split():\n",
    "        try: # Verifica se a palavra está contida na série da respectiva categoria. \n",
    "            prob *= (tabela_palavra_class_0[palavra] + smoothing['alpha']) / (len(lista_palavras_class_0) + smoothing['alpha']*smoothing['V']) \n",
    "        except: # Caso a palavra não exista, a técnica de smoothing impede que a probabilidade resulte em zero\n",
    "            prob *= smoothing['alpha'] / (len(lista_palavras_class_0) + smoothing['alpha']*smoothing['V'])\n",
    "                                                                              \n",
    "    return prob\n",
    "\n",
    "def prob_frase_dado_class_1(frase):\n",
    "    prob = 1\n",
    "    for palavra in frase.split():\n",
    "        try:\n",
    "            prob *= (tabela_palavra_class_1[palavra] + smoothing['alpha']) / (len(lista_palavras_class_1) + smoothing['alpha']*smoothing['V'])\n",
    "        except:\n",
    "            prob *= smoothing['alpha'] / (len(lista_palavras_class_1) + smoothing['alpha']*smoothing['V'])\n",
    "                                                                              \n",
    "    return prob\n",
    "\n",
    "def prob_frase_dado_class_2(frase):\n",
    "    prob = 1\n",
    "    for palavra in frase.split():\n",
    "        try:\n",
    "            prob *= (tabela_palavra_class_2[palavra] + smoothing['alpha']) / (len(lista_palavras_class_2) + smoothing['alpha']*smoothing['V'])\n",
    "        except:\n",
    "            prob *= smoothing['alpha'] / (len(lista_palavras_class_2) + smoothing['alpha']*smoothing['V'])\n",
    "                                                                              \n",
    "    return prob\n",
    "\n",
    "def prob_frase_dado_class_3(frase):\n",
    "    prob = 1\n",
    "    for palavra in frase.split():\n",
    "        try:\n",
    "            prob *= (tabela_palavra_class_3[palavra] + smoothing['alpha']) / (len(lista_palavras_class_3) + smoothing['alpha']*smoothing['V'])\n",
    "        except:\n",
    "            prob *= smoothing['alpha'] / (len(lista_palavras_class_3) + smoothing['alpha']*smoothing['V'])\n",
    "                                                                              \n",
    "    return prob\n",
    "\n",
    "def prob_frase_dado_class_4(frase):\n",
    "    prob = 1\n",
    "    for palavra in frase.split():\n",
    "        try:\n",
    "            prob *= (tabela_palavra_class_4[palavra] + smoothing['alpha']) / (len(lista_palavras_class_4) + smoothing['alpha']*smoothing['V'])\n",
    "        except:\n",
    "            prob *= smoothing['alpha'] / (len(lista_palavras_class_4) + smoothing['alpha']*smoothing['V'])\n",
    "                                                                              \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(tweet):\n",
    "    p_0_dado_frase = prob_frase_dado_class_0(tweet) * P_0\n",
    "    p_1_dado_frase = prob_frase_dado_class_1(tweet) * P_1\n",
    "    p_2_dado_frase = prob_frase_dado_class_2(tweet) * P_2\n",
    "    p_3_dado_frase = prob_frase_dado_class_3(tweet) * P_3\n",
    "    p_4_dado_frase = prob_frase_dado_class_4(tweet) * P_4\n",
    "    \n",
    "    # As probabilidade são guardadas em uma lista, para assim, retornar o maior valor dela\n",
    "    lista_de_probabilidades = [p_0_dado_frase,\n",
    "                               p_1_dado_frase,\n",
    "                               p_2_dado_frase,\n",
    "                               p_3_dado_frase,\n",
    "                               p_4_dado_frase]\n",
    "    \n",
    "    #Já que a lista está ordenada de acordo com as categorias, o index da maior probabilidade será a própria classificação\n",
    "    return lista_de_probabilidades.index(max(lista_de_probabilidades))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:,'NBayes'] = 0\n",
    "for i in range(len(test)):\n",
    "    test.iloc[i,2] = naive_bayes(test.Teste[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Teste[721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(test.Teste[721])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes(cleanup(test.Teste[721]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
